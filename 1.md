### 我想学习大数据
* 我想学习大数据却无从下手
* 大数据技术原理涉及的知识体系太庞大
* 我已经可以简单的操作Hadoop之后如何进一步提高自己

### 如何学习大数据
> 会用 -> 会想 -> 会玩

### 可以学到什么
* HBase是什么, 由哪些模块构成(基础知识)
* HBase的优缺点及应用场景
* HBase与常用关系型数据库的区别
* 如何操作HBase (通过Shell命令, Java API操作HBase)
* HBase的高级特性(过滤器, 协处理器，优化策略)
* HBase相关工具的使用(Phoenix 和 Sqoop)

### 对象存储服务实战
* 从需求开始，梳理功能点，确保HBase是一个合理的选择
* 根据业务场景设计两种解决方案，并进行讨论
* 动手实现解决方案一, 熟练的使用HBase解决业务问题

### 技术分析
* ObjectStore Web
    * 基于Spring Boot的web程序开发
* HBase
    * HBase开发测试环境的搭建与配置
    * 基于HBase Java API的程序开发
    * HBase表结构设计及调优
    * HBase读写流程解析及性能优化策略
    * 基于HBase的Phoenix产品的了解与使用
* Hadoop
    * Hadoop开发测试环境的搭建与配置
    * 基于Hadoop Java API的程序开发


### HBase 简介
* HBase是一个分布式的、面向列的开源数据库
* HBase在Hadoop之上提供了类似Bigtable的能力
* HBase不同于一般的关系型数据库，它适合非结构化数据存储

* BigTable是什么
* 什么是面向列的数据库
* 为什么HBase适合非结构化数据存储

### HBase在大数据生态圈中的位置
* HBase是Apache基金会顶级项目
* HBase基于Hadoop的核心HDFS系统进行数据存储, 类似于Hive
* HBase可以存储超大数据并适合用来进行大数据的实时查询

### HBase 与 HDFS
* HBase建立在Hadoop文件系统之上, 利用了Hadoop的文件系统的容错能力
* HBase提供对数据的随机实时读/写访问功能
* HBase内部使用哈希表, 并存储索引, 可将在HDFS文件中的数据进行快速查找

### HBase使用场景
* 瞬间写入量很大, 常用数据库不好支撑或需要很高成本支撑的场景
* 数据需要长久保存, 且量会持久增长到比较大的场景
* HBase不适用于有join, 多级索引, 表关系复杂的数据模型


### CAP 定理
* 一致性(所有节点在同一时间具有相同的数据)
* 可用性(保证每个请求不管成功或者失败都有响应，但不保证获取的数据为正确的数据)
* 分区容错性(系统中任意信息的丢失或失败不会影响系统的继续运作，系统如果不能在某一个时限内达成数据一致性，就必须在上面两个操作之间做出选择)

### ACID 定义
* 原子性
* 一致性
* 隔离性
* 持久性

### HBase 概念
* NameSpace: 可以把NameSpace理解为RDBMS的“数据库“
* Table: 表名必须是能用在文件路径里的合法名字
* Row: 在表里面, 每一行代表着一个数据对象, 每一行都是以一个行键(Row Key)来进行唯一标识的, 行键并没有什么特定的数据类型, 以二进制的字节来存储
* Column: HBase 的列由Column family和Column qualifier组成, 由冒号(:) 进行间隔, 比如family:qualifier

* RowKey: 可以唯一标识一行记录，不可被改变
* Column Family: 在定义HBase表的时候需要提前设置好列族，表中所有的列都需要组织在列族里面
* Column Qualifier: 列族中的数据通过列标识来进行映射, 可以理解为一个键值对，Column Qualifier就是Key
* Cell: 每一个 行键, 列族和列标识共同组成一个单元
* Timestamp: 每一个值都会有一个timestamp, 作为该值特定版本的标识符


### Hadoop 伪分布式集群安装配置
* 选择Hadoop version为2.7.3的版本并下载安装包
https://archive.apache.org/dist/hadoop/core/hadoop-2.7.3/
* 配置伪分布式环境
* 启动Hadoop集群, 并测试环境是否可以正常使用

* 配置免密登录
```ssh
ssh-keygen
cd .ssh
cat id_rsa.pub >> authorized_keys
chmod 600 authorized_keys

ssh localhost
```

* 配置jdk环境
```ssh
tar zxf jdk1.8.0_161.tar.gz
sudo mv jdk1.8.0_161/ /usr/local/

vi /etc/profile

export JAVA_HOME=/usr/local/jdk1.8.0_161
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH

wq

source /etc/profile

java -version
```

* 配置hadoop
```ssh
tar zxf hadoop-2.7.3.tar.gz

cd hadoop-2.7.3

cd etc/ hadoop

core-site.xml

hadoop.env.sh

hdfs-site.xml
```

* 更改hadoop.env.sh
```ssh
注释原有javahome
export JAVA_HOME=/usr/local/jdk1.8.0_161
```

* 更改hdfs-site.xml
```ssh
<configuraction>
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
<property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/home/echo/hadoop_data/dfs/name</value>
</property>
<property>
    <name>dfs.datanode.data.dir</name>
    <value>file:/home/echo/hadoop_data/dfs/data</value>
</property>
</configuraction>
```

* 更改core-site.xml
```ssh
<configuraction>
<property>
    <name>hadoop.tmp.dir</name>
    <value>file:/home/echo/hadoop_data</value>
</property>
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://0.0.0.0:9000</value>
</property>
</configuraction>
```

* 默认配置在哪里
```xml
google 
hdfs-default.xml
core-default.xml
```

* 启动hadoop
```ssh
进入hadoop的bin目录

./hdfs namenode -format
Exiting with status 0 表示执行成功

cd ..
cd sbin/

./start-dfs.sh

可以看到
namenode
datanode
secondaryNameNode
服务起来了

jps


cd ../bin/

./hdfs dfs -ls /

./hdfs dfs -mkdir /test

./hdfs dfs -ls /

到此 hadoop伪分布式集群已经创建成功啦
```

### HBase 伪分布式集群安装配置
* 选择HBase version 为1.2.4的版本并下载安装包
https://archive.apache.org/dist/hbase/1.2.4/

* 配置伪分布式环境

* 启动HBase，并测试环境是否可以正常使用

```sh
tar zxf hbase-1.2.4-bin.tar.gz
cd hbase-1.2.4
cd conf/
ls

cp hadoop的配置文件
cp hdfs-site.xml
cp core-site.xml 

vi hbase-env.sh
export JAVA_HOME=/usr/local/jdk1.8.0_161

注释掉 128m选项
vi hbase-site.xml

<configuraction>
<property>
    <name>hbase.rootdir</name>
    <value>hdfs://localhost:9000/hbase<value>
</property>
<property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/home/echo/hadoop_data/zookeeper<value>
</property>
<property>
    <name>hbase.cluster.distributed</name>
    <value>true<value>
</property>
</configuraction>

cd /bin
./start-hbase.sh
jps
./hbase shell
status
## 查看是否自动创建hdfs根目录
cd ../../hadoop-2.7.3/bin
./hdfs dfs -ls /

```

### HBase 基础架构
见手机

* HMaster
    * HMaster是HBase主／从集群架构中的中央节点
    * HMaster将region分配给RegionServer, 协调RegionServer的负载并维护集群的状态
    * 维护表和Region的元数据，不参与数据的输入／输出过程
* RegionServer
    * 维护HMaster分配给他的region, 处理对这些region的io请求
    * 负责切分正在运行过程中变的过大的region
* Zookeeper
    * Zookeeper是集群的协调器
    * HMaster启动将系统表加载到Zookeeper
    * 提供HBase RegionServer状态信息

### HBase 基础架构
* 一句话描述HBase
* HBase的基础概念
* HBase各个模块的作用

### HBase 写流程
* Client 会先访问zookeeper，得到对应的RegionServer地址
* Client对RegionServer发起写请求，RegionServer接受数据写入内存
* 当MemStore的大小达到一定的值后, flush到StoreFile并存储到HDFS

### HBase 读流程
* Client会先访问zookeeper, 得到对应的RegionServer地址
* Client对RegionServer发起读请求
* 当RegionServer收到client的读请求后, 先扫描自己的Memstore,再扫描BlockCache(加速读内容缓存区)如果还没找到则StoreFile中读取数据，然后将数据返回给Client

### HBase 各模块协作
* HBase启动时发生了什么
    * HMaster启动，注册到Zookeeper，等待RegionServer汇报
    * RegionServer注册到Zookeeper，并向HMaster汇报
    * 对各个RegionServer(包括失效的)的数据进行整理, 分配Region和meta信息
* 当RegionServer失效后会发生什么
    * HMaster将失效RegionServer上的Region分配到其他节点
    * HMaster更新hbase: meta表以保证数据正常访问
* 当HMaster失效后会发生什么
    * 处于Backup状态的其他HMaster节点推选出一个转为Active状态
    * 数据能正常读写，但是不能创建删除表，也不能更改表结构

### HBase 操作
* 通过shell命令操作HBase
    * status, list, create table
    * put, get, delete, scan

```ssh
./hbase shell
help 'status'

list

create 'FileTable', 'fileInfo', 'saveInfo'

list

desc

desc 'FileTable'

alter 'FileTable', 'cf'

desc 'FileTable'

alter 'FileTable', {NAME=> 'cf', METHOD=>'delete'}

put 'FileTable', 'rowkey1', 'fileInfo:name','file1.txt'
put 'FileTable', 'rowkey1', 'fileInfo:type','txt'
put 'FileTable', 'rowkey1', 'fileInfo:size','1024'

put 'FileTable', 'rowkey1', 'saveInfo:path','/home'
put 'FileTable', 'rowkey1', 'saveInfo:create','tom'

put 'FileTable', 'rowkey2', 'fileInfo:name','file2.txt'
put 'FileTable', 'rowkey2', 'fileInfo:type','avi'
put 'FileTable', 'rowkey2', 'fileInfo:size','2048'

put 'FileTable', 'rowkey2', 'saveInfo:path','/home'
put 'FileTable', 'rowkey2', 'saveInfo:create','echo'

count 'FileTable'

get 'FileTable', 'rowkey2'

get 'FileTable', 'rowkey1', 'fileInfo'

scan 'FileTable'

scan 'FileTable', {COLUMN=>'fileInfo:name'}

scan 'FileTable', {COLUMN=>'fileInfo'}

scan 'FileTable', {STARTROW=>'rowkey1',LIMIT=>1,VERSIONS=>1}
scan 'FileTable', {STARTROW=>'rowkey1',LIMIT=>2,VERSIONS=>1}

delete 'FileTable', 'rowkey1', 'fileInfo:size'

get 'FileTable', 'rowkey1', 'fileInfo:size'

deleteall 'FileTable', 'rowkey1'

get 'FileTable', 'rowkey1'

disable 'FileTable'

is_enabled 'FileTable'

is_disabled 'FileTable'

drop 'FileTable'

exists 'FileTable'

list
```
* 通过Java程序操作HBase
    * 开发HBase数据库操作类
        * 获取数据库链接
        * 增删改查模块编写
        * 增删改查方法测试
    * 通过多种过滤器过滤数据，实现HBase高级查询

* HBase数据过滤
    * 过滤器能干什么
        * HBase 为筛选数据提供了一组过滤器，通过过滤器可以在HBase中的数据的多个维度(行，列，数据版本)上进行对数据的筛选操作
        * 通常来说，通过行键、列来筛选数据的应用场景较多
    * 常用过滤器
        * PrefixFilter： 行的前缀匹配(行过滤器)
        * PageFilter： 基于行的分页(行过滤器)

        * ColumnPrefixFilter: 列前缀匹配 (列过滤器)
        * FirstKeyOnlyFilter: 只返回每一行的第一列 (列过滤器)

        * KeyOnlyFilter: 返回的数据不包括单元值，只包含行键与列 (基于单元值)
        * TimestampsFilter: 根据数据的时间戳版本进行过滤 (基于单元值)

        * SingleColumnValueFilter: 对该列的单元值进行比较过滤 (基于列和单元值的过滤器)
        * SingleColumnValueExcludeFilter: 对该列的单元值进行比较过滤 (基于列和单元值的过滤器)

        * 比较过滤器通常需要一个比较运算符以及一个比较器来实现过滤
        * RowFilter、FamilyFilter、QualifierFilter、ValueFilter

        * 自定义过滤器
            * 你真的需要自定义过滤器吗？
            * 如何实现自定义过滤器
    * 实战: 通过过滤器过滤数据


* 描述HBase的读写流程
* 如何通过Shell和Java API操作HBase
* HBase过滤器的使用

#### HBase 进阶
* 什么导致HBase性能下降
    * Jvm内存分配与GC回收策略
    * 与HBase运行机制相关的部分配置不合理
    * 表结构设计及用户使用方式不合理

* HBase数据存储过程
    * HBase写入时当memstore达到一定的大小会flush到磁盘保存成HFile, 当HFile小文件太多会执行compact操作进行合并
        * minor compaction: 选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile
        * major compaction: 将所有的StoreFile合并成一个StoreFile, 清理无意义数据: 被删除的数据、TTL过期数据、版本号超过设定版本号的数据
    * 当Region的大小达到某一个阀值之后，会执行split操作
        * split: 当一个region达到一定的大小就会自动split成两个region

    * HBase Compact检查
        * MemStore被flush到磁盘
        * 用户执行shell命令compact、major_compact或者调用了相应的API
        * HBase后台线程周期性触发检查
    * HBase 优化策略
        * 常见服务端配置优化
        * 常用优化策略(以实际需求为主)
        * HBase读／写性能优化
    
* HBase服务端优化
    * jvm设置与GC设置
    * hbase-site.xml部分属性配置

* HBase常用优化
    * 预先分区
        * 创建HBase表的时候会自动创建一个Region分区
        * 创建HBase表的时候预先创建一些空的Regions
    * RowKey优化
        * 利用HBase默认排序特点，将一起访问的数据放到一起
        * 防止热点问题，避免使用时序或者单调的递增递减等
    * Column优化
        * 列族的名称和列的描述命名尽量简短
        * 同一张表中ColumnFamily的数量不要超过3个
    * Schema优化
        * 宽表: 一种"列多行少"的设计
        * 高表: 一种"列少行多"的设计

* HBase写优化策略
    * 同步批量提交 or 异步批量提交
    * WAL优化，是否必须，持久化等级

* HBase读优化策略
    * 客户端: Scan缓存设置，批量获取
    * 服务端: BlockCache配置是否合理，HFile是否过多
    * 表结构设计问题

* HBase Coprocessor
    * HBase协处理器受BigTable协处理器的启发, 为用户提供类库和运行时环境，使得代码能够在HBase RegionServer和Master上处理
    * 系统协处理器 and 表协处理器
    * Observer and Endpoint
    * 系统协处理器: 全局加载到RegionServer托管的所有表和Region上
    * 表协处理器: 用户可以指定一张表使用协处理器
    * 观察者(Observer):类似于关系型数据库的触发器
        * RegionObserver: 提供客户端的数据操纵事件钩子: Get、Put、Delete、Scan等
        * MasterObserver: 提供DDL类型的操作钩子。如创建、删除、修改数据表等
        * WALObserver: 提供WAL相关操作钩子
    * Observer应用场景
        * 安全性: 例如执行Get或Put操作前，通过preGet或prePut方法检查是否允许该操作
        * 引用完整性约束: HBase并不支持关系型数据库中的引用完整性约束概念，即通常所说的外键。我们可以使用协处理器增强这种约束
        * 二级索引: 可以使用协处理器来维持一个二级索引
    * 终端(Endpoint):动态的终端有点像存储过程
    * Endpoint
        * Endpoint是动态RPC插件的接口，它的实现代码被安装在服务器端，从而能够通过HBase RPC唤醒
        * 调用接口，它们的实现代码会被目标RegionServer远程执行
        * 典型的案例: 一个大Table有几百个Region, 需要计算某列的平均值或者总和

### 手工实现协处理器
* 实现一个RegionObserver类型的协处理器 
* 实现一个Endpoint类型的协处理器

### HBase加载协处理器
* 配置文件加载: 即通过hbase.site.xml文件配置加载, 一般这样的协处理器是系统级别的 
* shell加载: 可以通过alter命令来对表进行schema修改来加载协处理器
* 通过API代码加载: 即通过API的方式来加载协处理器

### HBase卸载／更新协处理器
* 重复加载的第二个Coprocessor实例不会发挥作用 
* 要完成卸载／更新就需要重启JVM, 也就是重启RegionServer

### 项目实战 Object Store On HBase
* 需求
    * 我有非常多的文件需要存，以图片和文档为主，以后还有更多
    * 我只是想能快速的找到我需要的文件，不需要其他操作，很简单的
    * 作为一个伟大的程序员，你要尽量的节省资源

    * 老板要存非结构化数据，存很多文件，一直存
    * 老板想要快速查到文件，也许还想有其他操作，虽然他还没说
    * 老板想让马儿跑，还不把马儿喂饱

    * 小明最近接手了一个卫星项目，每天都有存储当天从卫星数据转换的图片，每天增量大概是数万张。图片存储之后他希望可以通过接口或者程序调用SDK快速的查询某个时间段的图片
    * 小红负责整理公司的各种文档数据，查找特定的文件很耗时，她想快速的找到某一份想要的文件，并且其他人无法看到相关的文件

* 用户到底需要什么
    * 海量非结构化数据，且呈爆发式增长，易扩容
    * 不需要复杂的文件管理与检索操作，需要很高的吞吐量
    * 还需要有一些权限控制的能力

* 功能概述
    * 文件管理: 上传、下载、删除、权限控制
    * 附加功能: 文件预览、接口及SDK
    * 这就是要一个对象存储啊

* 面向对象的存储
    * 以非结构化数据为主，如图片，文档，视频等
    * 使用简单有效且廉价的存储方式

* 对象存储服务
    * 数据作为单独的对象存储到一个大容器Bucket中
    * 应用通过唯一地址来识别每个单独的数据对象
    * 支持海量数据，高性能，可扩展，高可用

### 技术选型
* 优点
    * HBase可以很好的支持非结构化数据的存储，且基于HDFS保证数据可靠性
    * HBase吞吐量非常高，足够支撑业务
    * HBase基于Hadoop集群, 不需要重新维护其他数据存储服务

* 不足
    * HBase对小文件支持很好，但是大文件无法满足
    * 因为HBase的设计, HBase会发生compact和split操作。文件存储会比较频繁的出发此类耗时操作
    * HBase不适合复杂的检索操作，功能上可能有限制

* 大文件存储方案
    * 方案一: 将大文件分片存储到HBase中
    * 方案二: 将大文件存储到HDFS中, HBase只存储索引信息

* HBase优化方案
    * 将HBase的memstore尽量调大，避免文件上传频繁flush
    * 关闭自动major compact功能，改为手工合并，或者写脚本处理
    * 将hbase-site.xml中Region的大小设置大一些，建表时预先分区

* 复杂查询支持
    * HBase本身根据字典排序, 用户自行在文件夹文件名上做处理
    * 通过RowKey设计使其支持起始文件检索，文件前缀匹配等
    * 对象存储本身并不需要复杂的检索操作

* HOS Service 设计
    * web框架选取Spring Boot框架, 可以快速创建基于Spring的程序
    * 服务本身支持分布式，通过zookeeper实现分布式锁
    * 提供Restful Api和SDK供用户使用

    * 用户管理及权限管理模块(v1版本只对Bucket进行权限管理)
    * 文件管理核心模块
    * 接口及模块

* HOS 权限管理设计
    * 用户可以添加Token, 并且设定Token的过期时间
    * 用户可以将Bucket的访问权限授权给某个Token
    * 用户创建Bucket的时候, 默认将自己的ID作为Token对自己授权

* HOS 文件管理设计
    * Bucket信息存储到Mysql数据库, 文件及文件夹存储到HBase
    * 文件存储基于HBase可以快速的读取指定RowKey的文件
    * 可以基于HBase过滤器实现前缀，起止文件名的过滤操作

Zookeeper安装
* 下载zookeeper－3.4.9安装包
* 配置zookeeper并启动
* 将HBase的Zookeeper设置为部署的zookeeper节点

HBase优化
* 配置hbase-site.xml, 设置memstore的大小
* 配置hbase－site.xml, 设置region的大小
* 配置hbase-site.xml, 关闭major compact

```bash
停止hadoop
解压zookeeper

配置
zoo.cfg
server.1=localhost:2888:3888
mkdir /tmp/zookeeper
vi /tmp/zookeeper/myid
1
cd /bin
./zkServer.sh start
./zkServer.sh status

清空hadoop中的目录
重新格式化hadoop

配置habse的zk为false

vi hbase-site.xml
配置新的zookeeper

进入hbase 测试一下

Phoenix 测试

```

### HOS对象存储
用户管理模块
* 创建用户时，添加一条永久Token到Token表
* 删除用户时，删除用户的token及其token与bucket的权限映射
* 那么谁有权限创建用户？是否加入管理员角色

权限管理模块
* 用户只能管理（刷新，删除）由自己创建的Token
* 用户的Token的创建者为SuperAdmin

Bucket管理模块
* 创建Bucket的时候默认创建两个HBase表，一个为目录表，一个为文件表，并在HDFS创建对应的目录
* 删除Bucket的时候删除对应的HBase及HDFS文件夹
* 访问Bucket时需要验证Token的权限

文件管理模块
* 用户上传文件时，目录不存在支持多级创建，目录不为空不允许删除目录
* 将小文件存储到HBase，大文件存储到HDFS
* 用户A删除目录1时用户B正好向目录1上传文件怎么办？用户C正在向目录2上传文件，用户D将目录2删除了怎么办？
* 文件的seqid如何设计？最简单的是通过自增id生成
* seqid如何帮助我们过滤文件？
* hdfs的文件如何存储?

web服务与SDK模块
* 支持用户登录或者Header头信息带有Token信息访问
* 提供restful api, 对当前用户权限进行校验，返回操作状态
* SDK模块本质上为调用restful api实现相关操作

